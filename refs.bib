
@misc{abnt_abnt_2016,
  title   = {{ABNT} {NBR} 15606-2:2016  {Televisão} digital terrestre - {Codificação} de dados e especificações de transmissão para radiofusão digital  {Parte} 2: {Ginga}-{NCL} para receptores fixos e móveis - {Linguagem} de aplicação {XML} para codificação de aplicações},
  url     = {http://www.abntcatalogo.com.br/norma.aspx?ID=351837},
  urldate = {2016-08-08},
  author  = {{ABNT}},
  year    = {2016}
}

@article{allen_maintaining_1983,
  title   = {Maintaining {Knowledge} {About} {Temporal} {Intervals}},
  volume  = {26},
  issn    = {0001-0782},
  url     = {http://doi.acm.org/10.1145/182.358434},
  doi     = {10.1145/182.358434},
  number  = {11},
  urldate = {2014-05-29},
  journal = {Commun. ACM},
  author  = {Allen, James F.},
  month   = nov,
  year    = {1983},
  pages   = {832--843},
  file    = {Maintaining_Knowledge_About_Temporal_Intervals.pdf:/home/alan/gdrive/zotero/storage/G5MGVFKE/Maintaining_Knowledge_About_Temporal_Intervals.pdf:application/pdf}
}

@misc{andrew_hunt_speech_2004,
  title        = {Speech {Recognition} {Grammar} {Specification} {Version} 1.0},
  url          = {http://www.w3.org/TR/speech-grammar/},
  urldate      = {2016-08-02},
  author       = {W3C},
  collaborator = {{Andrew Hunt} and {Scott McGlashan}},
  year         = {2004}
}

@article{azevedo_composer:_2014,
  title      = {Composer: meeting non-functional aspects of hypermedia authoring environment},
  volume     = {70},
  issn       = {1380-7501, 1573-7721},
  shorttitle = {Composer},
  url        = {http://link.springer.com/article/10.1007/s11042-012-1216-8},
  doi        = {10.1007/s11042-012-1216-8},
  abstract   = {This paper discusses the importance of non-functional requirements in the design of hypermedia authoring tools, which typically provides multiple graphical abstractions (views). It focuses on creating products and services that operate robustly across a broad range of environments, and that take into account the changeable needs of their users over time, as they become more familiar with the tool. In order to meet these non-functional aspects, this paper proposes a microkernel-based architecture for authoring tools, where the microkernel is responsible for instantiating the requested extensions (plugins), maintaining the core data model that represents the hypermedia document under development, and notifying changes in this model to plugins interested in them. Based on the proposed architecture, a new version of Composer (an NCL authoring tool) is presented, rewritten from scratch. Results from experiments show that the discussed non-functional requirements are adequately met.},
  language   = {en},
  number     = {2},
  journal    = {Multimedia Tools and Applications},
  author     = {Azevedo, Roberto Gerson A. and Araújo, Eduardo Cruz and Lima, Bruno and Soares, Luiz Fernando G. and Moreno, Marcelo F.},
  month      = may,
  year       = {2014},
  pages      = {1199--1228}
}

@inproceedings{batista_estendendo_2010,
  title     = {Estendendo o uso das classes de dispositivos {Ginga}-{NCL}},
  url       = {http://www.lbd.dcc.ufmg.br/colecoes/webmedia/2010/04_webmi_c.pdf},
  booktitle = {{WebMedia} '10: {Proceedings} of the 16th {Brazilian} {Symposium} on {Multimedia} and the {Web}},
  publisher = {XVI Brazilian Symposium on Multimedia and the web, WebMedia ’10},
  author    = {Batista, Carlos Eduardo Coelho Freire and Soares, Luiz Fernando Gomes and de Souza Filho, Guido Lemos},
  year      = {2010}
}

@phdthesis{batista_ginga-md:_2013,
  title  = {{GINGA}-{MD}: {Uma} {Plataforma} para {Suporte} à {Execução} de {Aplicações} {Hipermídia} {Multi}-{Dispositivo} {Baseada} em {NCL}},
  url    = {https://doi.org/10.17771/PUCRio.acad.21956},
  school = {Pontifícia Universidade Católica do Rio de Janeiro},
  author = {Batista, Carlos Eduardo Coelho Freire},
  year   = {2013},
  file   = {GINGA-MD_-_Uma_Plataforma_para_Suporte_à_Execução_de_Aplicações_Hipermídia.PDF:/home/alan/gdrive/zotero/storage/WECUFA5I/GINGA-MD_-_Uma_Plataforma_para_Suporte_à_Execução_de_Aplicações_Hipermídia.PDF:application/pdf}
}

@inproceedings{beckham_towards_2001,
  title     = {Towards {SMIL} as a foundation for multimodal, multimedia applications},
  url       = {http://www.isca-speech.org/archive/eurospeech_2001/e01_1363.html},
  abstract  = {00026},
  urldate   = {2014-05-27},
  booktitle = {{EUROSPEECH} 2001 {Scandinavia}, 7th {European} {Conference} on {Speech} {Communication} and {Technology}},
  publisher = {ISCA},
  author    = {Beckham, Jennifer L. and Fabbrizio, Giuseppe Di and Klarlund, Nils},
  editor    = {Dalsgaard, Paul and Lindberg, Børge and Benner, Henrik and Tan, Zheng-Hua},
  year      = {2001},
  pages     = {1363--1366},
  file      = {Towards_SMIL_as_a_foundation_for_multimodal,_multimedia_applications.pdf:/home/alan/gdrive/zotero/storage/DC6QCZV9/Towards_SMIL_as_a_foundation_for_multimodal,_multimedia_applications.pdf:application/pdf}
}

@inproceedings{bolt_put-that-there:_1980,
  address    = {New York, NY, USA},
  title      = {Put-{That}-{There}: {Voice} and {Gesture} at the {Graphics} {Interface}},
  isbn       = {0-89791-021-4},
  shorttitle = {\&{Ldquo};{Put}-that-there\&{Rdquo};},
  url        = {http://doi.acm.org/10.1145/800250.807503},
  doi        = {10.1145/800250.807503},
  abstract   = {Recent technological advances in connected-speech recognition and position sensing in space have encouraged the notion that voice and gesture inputs at the graphics interface can converge to provide a concerted, natural user modality. The work described herein involves the user commanding simple shapes about a large-screen graphics display surface. Because voice can be augmented with simultaneous pointing, the free usage of pronouns becomes possible, with a corresponding gain in naturalness and economy of expression. Conversely, gesture aided by voice gains precision in its power to reference.},
  urldate    = {2014-05-15},
  booktitle  = {Proceedings of the 7th {Annual} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques}},
  publisher  = {ACM},
  author     = {Bolt, Richard A.},
  year       = {1980},
  pages      = {262--270},
  file       = {Put-That-There_-_Voice_and_Gesture_at_the_Graphics_Interface.pdf:/home/alan/gdrive/zotero/storage/PW486J92/Put-That-There_-_Voice_and_Gesture_at_the_Graphics_Interface.pdf:application/pdf}
}

@misc{brickley_foaf_2014,
  title   = {{FOAF} {Vocabulary} {Specification}},
  url     = {http://xmlns.com/foaf/spec/},
  urldate = {2016-08-02},
  author  = {Brickley, Dan and Miller, Libby},
  year    = {2014}
}

@book{bulterman_smil_2008,
  edition    = {2nd ed.},
  title      = {{SMIL} 3.0: Flexible Multimedia for Web, Mobile Devices and Daisy Talking Books},
  isbn       = {978-3-540-78546-0},
  shorttitle = {{SMIL} 3.0},
  publisher  = {Springer Publishing Company, Incorporated},
  author     = {Bulterman, Dick C.A. and Rutledge, Lloyd W.},
  date       = {2008},
  note       = {00084}
}

@article{bulterman_structured_2005,
  title        = {Structured Multimedia Authoring},
  volume       = {1},
  issn         = {1551-6857},
  url          = {http://doi.acm.org/10.1145/1047936.1047943},
  doi          = {10.1145/1047936.1047943},
  abstract     = {Authoring context sensitive, interactive multimedia presentations is much more complex than authoring either purely audiovisual applications or text. Interactions among media objects need to be described as a set of spatio-temporal relationships that account for synchronous and asynchronous interactions, as well as on-demand linking behavior. This article considers the issues that need to be addressed by an authoring environment. We begin with a partitioning of concerns based on seven classes of authoring problems. We then describe a selection of multimedia authoring environments within four different authoring paradigms: structured, timeline, graph and scripting. We next provide observations and insights into the authoring process and argue that the structured paradigm provides the most useful framework for presentation authoring. We close with an example application of the structured multimedia authoring paradigm in the context of our own structure-based system {GRiNS}.},
  pages        = {89--109},
  number       = {1},
  journaltitle = {{ACM} Trans. Multimedia Comput. Commun. Appl.},
  author       = {Bulterman, Dick C. A. and Hardman, Lynda},
  date         = {2005-02},
  note         = {00153}
}

@inproceedings{carvalho_architectures_2008,
  address   = {New York, NY, USA},
  title     = {Architectures for {Interactive} {Vocal} {Environment} to {Brazilian} {Digital} {TV} {Middleware}},
  isbn      = {978-1-59593-988-3},
  url       = {http://doi.acm.org/10.1145/1621087.1621109},
  doi       = {10.1145/1621087.1621109},
  abstract  = {Brazil began in 2007 a new phase in the transmission of terrestrial television: the deployment of Digital TV. Since the beginning, the Brazilian proposal has made it clear its association with digital inclusion as it arose a need of ensuring full accessibility and usability for users of terrestrial TV, among them individuals with special needs. It is in that context that emerges as an alternative the use of voice commands as a means of integrating these users. Using technologies such as voice gateway and VoiceXML language for voice interaction and Ginga as a platform for Digital TV, this work presents two architecture proposals to integrate these two technologies.},
  urldate   = {2014-06-10},
  booktitle = {Proceedings of the 2008 {Euro} {American} {Conference} on {Telematics} and {Information} {Systems}},
  publisher = {ACM},
  author    = {Carvalho, Lucas A. M. C. and Guimarães, Adolfo P. and Macêdo, Hendrik T.},
  year      = {2008},
  pages     = {22:1--22:8}
}

@inproceedings{carvalho_estendendo_2010,
  title     = {Estendendo a {NCL} para {Promover} {Interatividade} {Vocal} em {Aplicações} {Ginga} na {TVDi} {Brasileira}},
  abstract  = {00001},
  booktitle = {{WebMedia} '10: {Proceedings} of the 16th {Brazilian} {Symposium} on {Multimedia} and the {Web}},
  publisher = {Proceedings of the XIV Brazilian Symposium on Multimedia and the Web},
  author    = {Carvalho, Lucas and Macedo, Hendrik},
  year      = {2010},
  file      = {29_webmi_c.pdf:/home/alan/gdrive/zotero/storage/BBFKXJGI/29_webmi_c.pdf:application/pdf}
}

@incollection{costa_adapting_2011,
  title     = {Adapting {Multimodal} {Fission} to {User}’s {Abilities}},
  copyright = {©2011 Springer-Verlag GmbH Berlin Heidelberg},
  isbn      = {978-3-642-21671-8 978-3-642-21672-5},
  url       = {http://link.springer.com/chapter/10.1007/978-3-642-21672-5_38},
  abstract  = {New ways of communication are now possible thanks to adaptive multimodal systems, enabling the improvement in accessibility of ICT applications to all users. We are developing a project which combines TV with a multimodal system in order to overcome accessibility and usability problems by impaired users. This paper is focused on the fission of outputs, and how the presentations of applications running on GUIDE’s environment are adapted to the user’s capabilities.},
  urldate   = {2014-05-30},
  booktitle = {Universal {Access} in {Human}-{Computer} {Interaction}. {Design} for {All} and {eInclusion}},
  publisher = {Springer Berlin Heidelberg},
  author    = {Costa, David and Duarte, Carlos},
  editor    = {Stephanidis, Constantine},
  month     = jan,
  year      = {2011},
  pages     = {347--356},
  file      = {Adapting_Multimodal_Fission_to_User’s_Abilities.pdf:/home/alan/gdrive/zotero/storage/UIRW3DEV/Adapting_Multimodal_Fission_to_User’s_Abilities.pdf:application/pdf}
}

@incollection{coutaz_four_1995,
  series     = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
  title      = {Four {Easy} {Pieces} for {Assessing} the {Usability} of {Multimodal} {Interaction}: {The} {Care} {Properties}},
  isbn       = {978-1-5041-2898-8 978-1-5041-2896-4},
  shorttitle = {Four {Easy} {Pieces} for {Assessing} the {Usability} of {Multimodal} {Interaction}},
  url        = {https://link.springer.com/chapter/10.1007/978-1-5041-2896-4_19},
  abstract   = {We propose the CARE properties as a simple way of characterising and assessing aspects of multimodal interaction: the Complementarity, Assignment, Redundancy, and Equivalence that may occur between the interaction techniques available in a multimodal user interface. We provide a formal definition of these properties and use the notion of compatibility to show how the system CARE properties interact with user CARE-like properties in the design of a system. The discussion is illustrated with MATIS, a Multimodal Air Travel Information System.},
  language   = {en},
  urldate    = {2017-10-28},
  booktitle  = {Human—{Computer} {Interaction}},
  publisher  = {Springer, Boston, MA},
  author     = {Coutaz, Joëlle and Nigay, Laurence and Salber, Daniel and Blandford, Ann and May, Jon and Young, Richard M.},
  year       = {1995},
  pages      = {115--120}
}

@incollection{dahl_standards_2009,
  title     = {Standards for {Multimodal} {Interaction}},
  url       = {http://www.igi-global.com/book/multimodal-human-computer-interaction-pervasive/},
  abstract  = {00000},
  urldate   = {2015-04-13},
  booktitle = {Multimodal {Human} {Computer} {Interaction} and {Pervasive} {Services}},
  author    = {Dahl, Deborah A.},
  year      = {2009},
  pages     = {409},
  file      = {Standards_for_Multimodal_Interaction.pdf:/home/alan/gdrive/zotero/storage/HRXM8G6I/Standards_for_Multimodal_Interaction.pdf:application/pdf}
}

@misc{daniel_c._burnett_speech_2010,
  title        = {Speech {Synthesis} {Markup} {Language} ({SSML}) {Version} 1.1},
  url          = {http://www.w3.org/TR/speech-synthesis11/},
  urldate      = {2016-08-02},
  author       = {W3C},
  collaborator = {{Daniel C. Burnett} and {Zhi Wei Shuang}},
  year         = {2010}
}

@article{davis_perceived_1989,
  title    = {Perceived {Usefulness}, {Perceived} {Ease} of {Use}, and {User} {Acceptance} of {Information} {Technology}},
  volume   = {13},
  issn     = {0276-7783},
  url      = {http://www.jstor.org/stable/249008},
  doi      = {10.2307/249008},
  abstract = {Valid measurement scales for predicting user acceptance of computers are in short supply. Most subjective measures used in practice are unvalidated, and their relationship to system usage is unknown. The present research develops and validates new scales for two specific variables, perceived usefulness and perceived ease of use, which are hypothesized to be fundamental determinants of user acceptance. Definitions for these two variables were used to develop scale items that were pretested for content validity and then tested for reliability and construct validity in two studies involving a total of 152 users and four application programs. The measures were refined and stream-lined, resulting in two six-item scales with reliabilities of.98 for usefulness and.94 for ease of use. The scales exhibited high convergent, discriminant, and factorial validity. Perceived usefulness was significantly correlated with both self-reported current usage (r=.63, Study 1) and self-predicted future usage (r=.85, Study 2). Perceived ease of use was also significantly correlated with current usage (r=.45, Study 1) and future usage (r=.59, Study 2). In both studies, usefulness had a significantly greater correlation with usage behavior than did ease of use. Regression analyses suggest that perceived ease of use may actually be a causal antecedent to perceived usefulness, as opposed to a parallel, direct determinant of system usage. Implications are drawn for future research on user acceptance.},
  number   = {3},
  journal  = {MIS Quarterly},
  author   = {Davis, Fred D.},
  year     = {1989},
  pages    = {319--340},
  file     = {ART_1989_Davis_Perceived Usefulness, Perceived Ease of.pdf:/home/alan/gdrive/zotero/storage/6U7LTGFA/ART_1989_Davis_Perceived Usefulness, Perceived Ease of.pdf:application/pdf}
}

@inproceedings{de_salles_soares_neto_linguagens_2008,
  address    = {Porto Alegre, Brazil, Brazil},
  series     = {{IHC} '08},
  title      = {Linguagens {Computacionais} {Como} {Interfaces}: {Um} {Estudo} {Com} {Nested} {Context} {Language}},
  isbn       = {978-85-7669-203-4},
  shorttitle = {Linguagens {Computacionais} {Como} {Interfaces}},
  url        = {http://dl.acm.org/citation.cfm?id=1497470.1497489},
  abstract   = {This paper presents an empirical study about the Nested Context Language (NCL), which is a language developed to create multimedia documents and Interactive Digital TV (IDTV) applications for the Brazilian system. The goal was to obtain indicators of NCL usability in the generation of content for IDTV, since this language plays the role of interface language for users. Through data collected on forms filled by 220 students from various classes of training courses conducted in some states of Brazil and later analysis by a mix of qualitative and quantitative methods, some aspects were found where the NCL profile can and should be improved in order to ease the activities of content creators for IDTV, who have a heterogeneous profile and are not necessarily familiar with computer programming.},
  urldate    = {2016-12-12},
  booktitle  = {Proceedings of the {VIII} {Brazilian} {Symposium} on {Human} {Factors} in {Computing} {Systems}},
  publisher  = {Sociedade Brasileira de Computação},
  author     = {de Salles Soares Neto, Carlos and de Souza, Clarisse Sieckenius and Soares, Luiz Fernando Gomes},
  year       = {2008},
  pages      = {166--175},
  file       = {ACM Full Text PDF:/home/alan/gdrive/zotero/storage/JCTPMU7G/Linguagens Computacionais Como Interfaces Um Estudo Com Nested Context Language.pdf:application/pdf}
}

@inproceedings{dietz_diamondtouch:_2001,
  title      = {{DiamondTouch}: a multi-user touch technology},
  shorttitle = {{DiamondTouch}},
  url        = {http://dl.acm.org/citation.cfm?id=502389},
  urldate    = {2016-05-06},
  booktitle  = {Proceedings of the 14th annual {ACM} symposium on {User} interface software and technology},
  publisher  = {ACM},
  author     = {Dietz, Paul and Leigh, Darren},
  year       = {2001},
  pages      = {219--226}
}

@article{dumas_description_2010,
  title      = {Description languages for multimodal interaction: a set of guidelines and its illustration with {SMUIML}},
  volume     = {3},
  issn       = {1783-7677, 1783-8738},
  shorttitle = {Description languages for multimodal interaction},
  url        = {http://link.springer.com/article/10.1007/s12193-010-0043-3},
  doi        = {10.1007/s12193-010-0043-3},
  abstract   = {This article introduces the problem of modeling multimodal interaction, in the form of markup languages. After an analysis of the current state of the art in multimodal interaction description languages, nine guidelines for languages dedicated at multimodal interaction description are introduced, as well as four different roles that such language should target: communication, configuration, teaching and modeling. The article further presents the SMUIML language, our proposed solution to improve the time synchronicity aspect while still fulfilling other guidelines. SMUIML is finally mapped to these guidelines as a way to evaluate their spectrum and to sketch future works.},
  language   = {en},
  number     = {3},
  urldate    = {2014-05-30},
  journal    = {Journal on Multimodal User Interfaces},
  author     = {Dumas, Bruno and Lalanne, Denis and Ingold, Rolf},
  month      = apr,
  year       = {2010},
  pages      = {237--247},
  file       = {Description_languages_for_multimodal_interaction_-_a_set_of_guidelines_and_its_illustration_with.pdf:/home/alan/gdrive/zotero/storage/9DWT893I/Description_languages_for_multimodal_interaction_-_a_set_of_guidelines_and_its_illustration_with.pdf:application/pdf}
}

@phdthesis{dumas_frameworks_2010,
  title    = {Frameworks, description languages and fusion engines for multimodal interactive systems},
  url      = {https://doc.rero.ch/record/21372/files/DumasB.pdf},
  abstract = {00012},
  urldate  = {2015-02-19},
  school   = {Faculty of Science, University of Fribourg (Switzerland},
  author   = {Dumas, Bruno},
  year     = {2010},
  file     = {Frameworks,_description_languages_and_fusion_engines_for_multimodal_interactive_systems.pdf:/home/alan/gdrive/zotero/storage/QGBSNRJW/Frameworks,_description_languages_and_fusion_engines_for_multimodal_interactive_systems.pdf:application/pdf}
}

@incollection{dumas_multimodal_2009,
  title      = {Multimodal {Interfaces}: {A} {Survey} of {Principles}, {Models} and {Frameworks}},
  copyright  = {©2009 Springer Berlin Heidelberg},
  isbn       = {978-3-642-00436-0 978-3-642-00437-7},
  shorttitle = {Multimodal {Interfaces}},
  url        = {http://link.springer.com/chapter/10.1007/978-3-642-00437-7_1},
  abstract   = {The grand challenge of multimodal interface creation is to build reliable processing systems able to analyze and understand multiple communication means in real-time. This opens a number of associated issues covered by this chapter, such as heterogeneous data types fusion, architectures for real-time processing, dialog management, machine learning for multimodal interaction, modeling languages, frameworks, etc. This chapter does not intend to cover exhaustively all the issues related to multimodal interfaces creation and some hot topics, such as error handling, have been left aside. The chapter starts with the features and advantages associated with multimodal interaction, with a focus on particular findings and guidelines, as well as cognitive foundations underlying multimodal interaction. The chapter then focuses on the driving theoretical principles, time-sensitive software architectures and multimodal fusion and fission issues. Modeling of multimodal interaction as well as tools allowing rapid creation of multimodal interfaces are then presented. The article concludes with an outline of the current state of multimodal interaction research in Switzerland, and also summarizes the major future challenges in the field.},
  language   = {en},
  urldate    = {2015-05-05},
  booktitle  = {Human {Machine} {Interaction}},
  publisher  = {Springer Berlin Heidelberg},
  author     = {Dumas, Bruno and Lalanne, Denis and Oviatt, Sharon},
  editor     = {Lalanne, Denis and Kohlas, Jürg},
  year       = {2009},
  pages      = {3--26},
  file       = {Multimodal_Interfaces_-_A_Survey_of_Principles,_Models_and_Frameworks.pdf:/home/alan/gdrive/zotero/storage/Q376BHAJ/Multimodal_Interfaces_-_A_Survey_of_Principles,_Models_and_Frameworks.pdf:application/pdf}
}

@inproceedings{dumas_prototyping_2008,
  title     = {Prototyping multimodal interfaces with smuiml modeling language},
  abstract  = {00010},
  booktitle = {{CHI} 2008 {Workshop} on {User} {Interface} {Description} {Languages} for {Next} {Generation} {User} {Interfaces}, {CHI}},
  author    = {Dumas, B and Lalanne, D and Ingold, R},
  year      = {2008},
  pages     = {63--66},
  file      = {Full Text PDF:/home/alan/gdrive/zotero/storage/9ZGFWJZY/Prototyping Multimodal Interfaces with the SMUIML Modeling Language.pdf:application/pdf}
}

@incollection{elmqvist_distributed_2011,
  title      = {Distributed {User} {Interfaces}: {State} of the {Art}},
  copyright  = {©2011 Springer-Verlag London Limited},
  isbn       = {978-1-4471-2270-8 978-1-4471-2271-5},
  shorttitle = {Distributed {User} {Interfaces}},
  url        = {http://link.springer.com/chapter/10.1007/978-1-4471-2271-5_1},
  abstract   = {We summarize the state of the art in the field of distributed user interfaces (DUIs). Topics surveyed include pervasive and ubiquitous computing, migratory and migratable interfaces, plasticity and adaptivity in interaction, and applications to multi-display and multi-surface environments. Based on this survey, we then draw some general conclusions on past and current research within the field. Our purpose is to provide a solid foundation for future research in distributed user interfaces.},
  language   = {en},
  urldate    = {2015-04-12},
  booktitle  = {Distributed {User} {Interfaces}},
  publisher  = {Springer London},
  author     = {Elmqvist, Niklas},
  editor     = {Gallud, José A. and Tesoriero, Ricardo and Penichet, Victor M. R.},
  year       = {2011},
  pages      = {1--12},
  file       = {Distributed_User_Interfaces_-_State_of_the_Art.pdf:/home/alan/gdrive/zotero/storage/2ICCQSKW/Distributed_User_Interfaces_-_State_of_the_Art.pdf:application/pdf}
}

@article{fernando_o_2009,
  title  = {O uso da linguagem declarativa do ginga-ncl na construção de conteúdos audiovisuais interativos: a experiência do “roteiros do dia”},
  author = {Fernando, Luiz and Soares, Gomes},
  year   = {2009},
  file   = {O_uso_da_linguagem_declarativa_do_ginga-ncl_na_construção_de_conteúdos_audiovisuais_interativos_-_a.pdf:/home/alan/gdrive/zotero/storage/2FDCFCKJ/O_uso_da_linguagem_declarativa_do_ginga-ncl_na_construção_de_conteúdos_audiovisuais_interativos_-_a.pdf:application/pdf}
}

@article{gefen_impact_1998,
  title      = {The {Impact} of {Developer} {Responsiveness} on {Perceptions} of {Usefulness} and {Ease} of {Use}: {An} {Extension} of the {Technology} {Acceptance} {Model}},
  volume     = {29},
  issn       = {0095-0033},
  shorttitle = {The {Impact} of {Developer} {Responsiveness} on {Perceptions} of {Usefulness} and {Ease} of {Use}},
  url        = {http://doi.acm.org/10.1145/298752.298757},
  doi        = {10.1145/298752.298757},
  abstract   = {The Technology Acceptance Model (TAM) suggests that the perceived usefulness (PU) and the perceived ease of use (PEOU) of an information system (IS) are major determinants of its use. Previous research has demonstrated the validity of this model across a wide variety of IS types. However, prior research has not identified antecedents of PU and there has been only limited research on the antecedents of PEOU. Consequently, research has provided little guidance to IS managers on methods to increase use by augmenting PU and PEOU.Viewing IS development as an instance of Social Exchange Theory (SET), this study proposes that IS managers can influence both the PU and the PEOU of an IS through a constructive social exchange with the user. One means of building and maintaining a constructive social exchange is through developer responsiveness. The results of this study, examining the adoption of an expert system, indeed support this notion. Specifically, developer responsiveness strongly influenced both PU and PEOU, but only indirectly affected actual behavior --- IS use --- in accordance with the predictions of SET. An extension of TAM based on SET is presented and the implications of this extended model are discussed from both a managerial and theoretical perspective.},
  number     = {2},
  journal    = {SIGMIS Database},
  author     = {Gefen, David and Keil, Mark},
  month      = apr,
  year       = {1998},
  pages      = {35--49},
  file       = {ACM Full Text PDF:/home/alan/gdrive/zotero/storage/E6UVTPY3/The Impact of Developer Responsiveness on Perceptions of Usefulness and Ease of Use An Extension of the Technology Acceptance Model.pdf:application/pdf}
}

@article{ghinea_mulsemedia:_2014,
  title      = {Mulsemedia: {State} of the {Art}, {Perspectives}, and {Challenges}},
  volume     = {11},
  issn       = {1551-6857},
  shorttitle = {Mulsemedia},
  url        = {http://doi.acm.org/10.1145/2617994},
  doi        = {10.1145/2617994},
  abstract   = {Mulsemedia—multiple sensorial media—captures a wide variety of research efforts and applications. This article presents a historic perspective on mulsemedia work and reviews current developments in the area. These take place across the traditional multimedia spectrum—from virtual reality applications to computer games—as well as efforts in the arts, gastronomy, and therapy, to mention a few. We also describe standardization efforts, via the MPEG-V standard, and identify future developments and exciting challenges the community needs to overcome.},
  number     = {1s},
  urldate    = {2014-10-21},
  journal    = {ACM Transactions on Multimedia Computing, Communications, and Applications},
  author     = {Ghinea, Gheorghita and Timmerer, Christian and Lin, Weisi and Gulliver, Stephen R.},
  month      = oct,
  year       = {2014},
  pages      = {17:1--17:23},
  file       = {Mulsemedia_-_State_of_the_Art,_Perspectives,_and_Challenges.pdf:/home/alan/gdrive/zotero/storage/2N9PH3E6/Mulsemedia_-_State_of_the_Art,_Perspectives,_and_Challenges.pdf:application/pdf}
}

@misc{google_supporting_nodate,
  title   = {Supporting {Multiple} {Game} {Controllers} {\textbar} {Android} {Developers}},
  url     = {https://developer.android.com/intl/pt-br/training/game-controllers/multiple-controllers.html},
  urldate = {2016-05-02},
  author  = {{Google}}
}

@article{guedes_extending_2016,
  title    = {Extending multimedia languages to support multimodal user interactions},
  issn     = {1380-7501, 1573-7721},
  url      = {http://link.springer.com/article/10.1007/s11042-016-3846-8},
  doi      = {10.1007/s11042-016-3846-8},
  abstract = {Historically, the Multimedia community research has focused on output modalities, through studies on timing and multimedia processing. The Multimodal Interaction community, on the other hand, has focused on user-generated modalities, through studies on Multimodal User Interfaces (MUI). In this paper, aiming to assist the development of multimedia applications with MUIs, we propose the integration of concepts from those two communities in a unique high-level programming framework. The framework integrates user modalities —both user-generated (e.g., speech, gestures) and user-consumed (e.g., audiovisual, haptic)— in declarative programming languages for the specification of interactive multimedia applications. To illustrate our approach, we instantiate the framework in the NCL (Nested Context Language) multimedia language. NCL is the declarative language for developing interactive applications for Brazilian Digital TV and an ITU-T Recommendation for IPTV services. To help evaluate our approach, we discuss a usage scenario and implement it as an NCL application extended with the proposed multimodal features. Also, we compare the expressiveness of the multimodal NCL against existing multimedia and multimodal languages, for both input and output modalities.},
  language = {en},
  urldate  = {2016-11-27},
  journal  = {Multimedia Tools and Applications},
  author   = {Guedes, Alan Livio Vasconcelos and Azevedo, Roberto Gerson de Albuquerque and {Simone Diniz Junqueira Barbosa}},
  month    = oct,
  year     = {2016},
  pages    = {1--30},
  file     = {Full Text PDF:/home/alan/gdrive/zotero/storage/K4WLYHN9/Extending multimedia languages to support multimodal user interactions.pdf:application/pdf}
}

@inproceedings{guedes_extending_2016-1,
  address   = {New York, NY, USA},
  series    = {Webmedia '16},
  title     = {Extending {NCL} to {Support} {Multiuser} and {Multimodal} {Interactions}},
  isbn      = {978-1-4503-4512-5},
  url       = {http://doi.acm.org/10.1145/2976796.2976869},
  doi       = {10.1145/2976796.2976869},
  abstract  = {Recent advances in technologies for speech, touch and gesture recognition have given rise to a new class of user interfaces that does not only explore multiple modalities but also allows for multiple interacting users. Even so, current declarative multimedia languages e.g. HTML, SMIL, and NCL?support only limited forms of user input (mainly keyboard and mouse) for a single user. In this paper, we aim at studying how the NCL multimedia language could take advantage of those new recognition technologies. To do so, we revisit the model behind NCL, named NCM (Nested Context Model), and extend it with first-class concepts supporting multiuser and multimodal features. To evaluate our approach, we instantiate the proposal and discuss some usage scenarios, developed as NCL applications with our extended features.},
  urldate   = {2016-12-01},
  booktitle = {Proceedings of the 22Nd {Brazilian} {Symposium} on {Multimedia} and the {Web}},
  publisher = {ACM},
  author    = {Guedes, Alan Livio Vasconcelos and de Albuquerque Azevedo, Roberto G. and Colcher, Sérgio and Barbosa, Simone D.J.},
  year      = {2016},
  pages     = {39--46},
  file      = {ACM Full Text PDF:/home/alan/gdrive/zotero/storage/RQVCEVVK/Extending NCL to Support Multiuser and Multimodal Interactions.pdf:application/pdf}
}


@inproceedings{guedes_specification_2015,
  address   = {New York, NY, USA},
  series    = {{WebMedia} '15},
  title     = {Specification of {Multimodal} {Interactions} in {NCL}},
  isbn      = {978-1-4503-3959-9},
  url       = {http://doi.acm.org/10.1145/2820426.2820436},
  doi       = {10.1145/2820426.2820436},
  abstract  = {This paper proposes an approach to integrate multimodal events--both user-generated, e.g., audio recognizer, motion sensors; and user-consumed, e.g., speech synthesizer, haptic synthesizer--into programming languages for the declarative specification of multimedia applications. More precisely, it presents extensions to the NCL (Nested Context Language) multimedia language. NCL is the standard declarative language for the development of interactive applications for Brazilian Digital TV and an ITU-T Recommendation for IPTV services. NCL applications extended with the multimodal features are presented as results. Historically, Human-Computer Interaction research community has been focusing on user-generated modalities, through studies on the user interaction. On the other hand, Multimedia community has been focusing on output modalities, through studies on timing and multimedia processing. The proposals in this paper is an attempt to integrate concepts of both research communities in a unique high-level programming framework, which aims to assist the authoring of multimedia/multimodal applications.},
  booktitle = {Proceedings of the 21st {Brazilian} {Symposium} on {Multimedia} and the {Web}},
  publisher = {ACM},
  author    = {Guedes, Alan Livio Vasconcelos and Azevedo, Roberto Gerson de Albuquerque and Moreno, Marcio Ferreira and Soares, Luiz Fernando Gomes},
  year      = {2015},
  pages     = {181--187},
  file      = {ACM Full Text PDF:/home/alan/gdrive/zotero/storage/E9QHP3DA/Specification of Multimodal Interactions in NCL.pdf:application/pdf}
}

@inproceedings{guedes_towards_2016,
  address    = {New York, NY, USA},
  series     = {{DocEng} '16},
  title      = {Towards {Supporting} {Multimodal} and {Multiuser} {Interactions} in {Multimedia} {Languages}},
  isbn       = {978-1-4503-4438-8},
  shorttitle = {Doctoral {Consortium}},
  booktitle  = {In: {Doctoral} {Consortium}. {Proceedings} of the 2016 {ACM} {Symposium} on {Document} {Engineering}},
  publisher  = {ACM},
  author     = {Guedes, Alan Livio Vasconcelos},
  year       = {2016},
  file       = {Towards_Supporting_Multimodal_and_Multiuser_Interactions_in_Multimedia_Languages.pdf:/home/alan/gdrive/zotero/storage/CQLDSVXH/Towards_Supporting_Multimodal_and_Multiuser_Interactions_in_Multimedia_Languages.pdf:application/pdf}
}

@inproceedings{guedes_using_2016,
  address   = {New York, NY, USA},
  series    = {{WebMedia} '16},
  title     = {Using {NCL} to {Synchronize} {Media} {Objects}, {Sensors} and {Actuators}},
  isbn      = {978-85-7669-332-1},
  url       = {http://www.lbd.dcc.ufmg.br/colecoes/wsotwebmedia/2016/003.pdf},
  booktitle = {In: {Workshop} {Internacional} de {Sincronismo} das {Coisas} ({WSoT}), 1, 2016, {Teresina}. {Anais} do {XXII} {Simpósio} {Brasileiro} de {Sistemas} {Multimídia} e {Web}. {Porto} {Alegre}: {Sociedade} {Brasileira} de {Computação}, 2016. v. 2},
  publisher = {ACM},
  author    = {Guedes, Alan Livio Vasconcelos and {Marcio Cunha} and {Hugo Fuks} and {Sérgio Colcher} and {Simone Diniz Junqueira Barbosa}},
  year      = {2016}
}

@inproceedings{guerrero_garcia_designing_2010,
  title     = {Designing workflow user interfaces with {UsiXML}},
  url       = {http://dial.uclouvain.be/downloader/downloader.php?pid=boreal:118234&datastream=PDF_01},
  urldate   = {2016-05-06},
  booktitle = {1st {Int}. {Workshop} on {User} {Interface} {eXtensible} {Markup} {Language} {UsiXML}'2010},
  author    = {Guerrero Garcia, Josefina and Vanderdonckt, Jean and {others}},
  year      = {2010}
}

@inproceedings{haber_modeling_2001,
  title     = {Modeling {Multiuser} {Interactions}},
  url       = {http://eculturenet.org/mmi/euro-cscl/Papers/63.pdf},
  urldate   = {2016-04-13},
  booktitle = {Proceedings at the {First} {European} {Computer} {Supported} {Collaborative} {Learning} {Conference}, {Maastricht}, {Germany}},
  author    = {Haber, Cornelia},
  year      = {2001},
  pages     = {22--24},
  file      = {Modeling_Multiuser_Interactions.pdf:/home/alan/gdrive/zotero/storage/IN3KSJ5F/Modeling_Multiuser_Interactions.pdf:application/pdf}
}

@article{hachaj_rule-based_2014,
  title    = {Rule-based approach to recognizing human body poses and gestures in real time},
  volume   = {20},
  issn     = {0942-4962, 1432-1882},
  url      = {http://link.springer.com/article/10.1007/s00530-013-0332-2},
  doi      = {10.1007/s00530-013-0332-2},
  abstract = {In this paper we propose a classifier capable of recognizing human body static poses and body gestures in real time. The method is called the gesture description language (GDL). The proposed methodology is intuitive, easily thought and reusable for any kind of body gestures. The very heart of our approach is an automated reasoning module. It performs forward chaining reasoning (like a classic expert system) with its inference engine every time new portion of data arrives from the feature extraction library. All rules of the knowledge base are organized in GDL scripts having the form of text files that are parsed with a LALR-1 grammar. The main novelty of this paper is a complete description of our GDL script language, its validation on a large dataset (1,600 recorded movement sequences) and the presentation of its possible application. The recognition rate for examined gestures is within the range of 80.5–98.5 \%. We have also implemented an application that uses our method: it is a three-dimensional desktop for visualizing 3D medical datasets that is controlled by gestures recognized by the GDL module.},
  language = {en},
  number   = {1},
  urldate  = {2017-02-02},
  journal  = {Multimedia Systems},
  author   = {Hachaj, Tomasz and Ogiela, Marek R.},
  month    = feb,
  year     = {2014},
  pages    = {81--99}
}

@incollection{hachaj_semantic_2012,
  series    = {Communications in {Computer} and {Information} {Science}},
  title     = {Semantic {Description} and {Recognition} of {Human} {Body} {Poses} and {Movement} {Sequences} with {Gesture} {Description} {Language}},
  copyright = {©2012 Springer-Verlag Berlin Heidelberg},
  isbn      = {978-3-642-35520-2 978-3-642-35521-9},
  url       = {http://link.springer.com/chapter/10.1007/978-3-642-35521-9_1},
  abstract  = {In this article we introduce new approach for human body poses and movement sequences recognition. Our concept is based on syntactic description with so called Gesture Description Language (GDL). The implementation of GDL requires special semantic reasoning module with additional heap-like memory. In the following paragraphs we shortly describes our initial concept. We also present software and hardware architecture that we created to test our solution and very promising early experiments results.},
  language  = {en},
  number    = {353},
  urldate   = {2016-08-16},
  booktitle = {Computer {Applications} for {Bio}-technology, {Multimedia}, and {Ubiquitous} {City}},
  publisher = {Springer Berlin Heidelberg},
  author    = {Hachaj, Tomasz and Ogiela, Marek R.},
  editor    = {Kim, Tai-hoon and Kang, Jeong-Jin and Grosky, William I. and Arslan, Tughrul and Pissinou, Niki},
  year      = {2012},
  pages     = {1--8}
}

@article{huang_synchronization_1998,
  title    = {Synchronization for interactive multimedia presentations},
  volume   = {5},
  issn     = {1070-986X},
  doi      = {10.1109/93.735868},
  abstract = {When multimedia presentations allow users to make online adjustments such as reverse, skip, freeze-restart, and scale, maintaining temporal synchrony among several media streams becomes a complex modeling problem. Our approach uses dynamic extended finite-state machines for the task-an “actor” DEFSM for each medium and a “synchronizer” DEFSM to orchestrate them. This model achieves clear state-transition control flow and allows concise, precise specifications},
  number   = {4},
  journal  = {IEEE MultiMedia},
  author   = {Huang, Chung-Ming and Wang, Chian},
  month    = oct,
  year     = {1998},
  pages    = {44--62}
}

@incollection{hutchison_towards_2006,
  address    = {Berlin, Heidelberg},
  title      = {Towards a {Common} {Framework} for {Multimodal} {Generation}: {The} {Behavior} {Markup} {Language}},
  volume     = {4133},
  isbn       = {978-3-540-37593-7 978-3-540-37594-4},
  shorttitle = {Towards a {Common} {Framework} for {Multimodal} {Generation}},
  url        = {http://link.springer.com/10.1007/11821830_17},
  urldate    = {2016-06-17},
  booktitle  = {Intelligent {Virtual} {Agents}},
  publisher  = {Springer Berlin Heidelberg},
  author     = {Kopp, Stefan and Krenn, Brigitte and Marsella, Stacy and Marshall, Andrew N. and Pelachaud, Catherine and Pirker, Hannes and Thórisson, Kristinn R. and Vilhjálmsson, Hannes},
  editor     = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Gratch, Jonathan and Young, Michael and Aylett, Ruth and Ballin, Daniel and Olivier, Patrick},
  year       = {2006},
  pages      = {205--217}
}

@misc{ideum_inc_gesture_2016,
  title   = {Gesture {Markup} {Language}},
  url     = {http://www.gestureml.org/},
  urldate = {2016-03-03},
  author  = {{Ideum Inc}},
  year    = {2016}
}


@misc{iso/iec_iso/iec_2013,
  title   = {{ISO}/{IEC} 23005-3:2013 {Information} {Technology} - {Media} {Context} and {Control} - {Part} 3: {Sensory} {Information}},
  url     = {www.iso.org/iso/home/store/catalogue_ics/catalogue_detail_ics.htm?csnumber=60391},
  urldate = {2016-08-08},
  author  = {{ISO/IEC}},
  year    = {2013}
}

@misc{iso/iec_iso/iec_2014,
  title      = {{ISO}/{IEC} 23005-1:2014 - {Information} technology -- {Media} context and control -- {Part} 1: {Architecture}},
  shorttitle = {{ISO}/{IEC} 23005-1},
  url        = {http://www.iso.org/iso/catalogue_detail.htm?csnumber=60359},
  urldate    = {2016-08-08},
  author     = {{ISO/IEC}},
  year       = {2014}
}

@article{jaimes_multimodal_2007,
  series     = {Special {Issue} on {Vision} for {Human}-{Computer} {Interaction}},
  title      = {Multimodal human–computer interaction: {A} survey},
  volume     = {108},
  issn       = {1077-3142},
  shorttitle = {Multimodal human–computer interaction},
  url        = {http://www.sciencedirect.com/science/article/pii/S1077314206002335},
  doi        = {10.1016/j.cviu.2006.10.019},
  abstract   = {In this paper, we review the major approaches to multimodal human–computer interaction, giving an overview of the field from a computer vision perspective. In particular, we focus on body, gesture, gaze, and affective interaction (facial expression recognition and emotion in audio). We discuss user and task modeling, and multimodal fusion, highlighting challenges, open issues, and emerging applications for multimodal human–computer interaction (MMHCI) research.},
  number     = {1},
  urldate    = {2017-10-28},
  journal    = {Computer Vision and Image Understanding},
  author     = {Jaimes, Alejandro and Sebe, Nicu},
  month      = oct,
  year       = {2007},
  pages      = {116--134}
}

@incollection{katsurada_xisl:_2005,
  title      = {{XISL}: {A} {Modality}-{Independent} {MMI} {Description} {Language}},
  copyright  = {©2005 Springer},
  isbn       = {978-1-4020-3073-4 978-1-4020-3075-8},
  shorttitle = {{XISL}},
  url        = {http://link.springer.com/chapter/10.1007/1-4020-3075-4_8},
  abstract   = {In this chapter we outline a multimodal interaction description language XISL (eXtensible Interaction Scenario Language) that has been developed to describe MMI scenarios. The main feature of XISL is that it allows modalities to be described flexibly, which makes it easy to add new modalities or to modify existing modalities on MMI systems. Moreover, XISL is separately described from XML or HTML contents, thus making both the XISL and XML (HTML) documents more reusable. We constructed three types of XISL execution systems, namely a PC terminal, a PDA terminal, and a mobile phone terminal, and show the descriptive power of XISL by implementing an online shopping application on these terminals.},
  urldate    = {2014-06-10},
  booktitle  = {Spoken {Multimodal} {Human}-{Computer} {Dialogue} in {Mobile} {Environments}},
  publisher  = {Springer Netherlands},
  author     = {Katsurada, Kouichi and Yamada, Hirobumi and Nakamura, Yusaku and Kobayashi, Satoshi and Nitta, Tsuneo},
  editor     = {Minker, W. and Bühler, Dirk and Dybkjær, Laila},
  month      = jan,
  year       = {2005},
  pages      = {133--148},
  file       = {XISL_-_A_Modality-Independent_MMI_Description_Language.pdf:/home/alan/gdrive/zotero/storage/WNM6JEK8/XISL_-_A_Modality-Independent_MMI_Description_Language.pdf:application/pdf}
}

@inproceedings{laurence_nigay_multifeature_1997,
  title      = {Multifeature {Systems}: {The} {CARE} {Properties} and {Their} {Impact} on {Software} {Design}},
  shorttitle = {Multifeature {Systems}},
  abstract   = {Multifeature user interfaces support multiple interaction techniques which may be used sequentially or concurrently, and independently or combined synergistically (Nigay, Coutaz 1993a). New interaction aspects must be considered, such as the fusion and fission of information, and the nature of temporal constraints. The availability of multiple interaction techniques opens a new world of experience, but our understanding of how they relate to each other is still unclear. We propose here a unified framework based on the notions of interaction language and physical device. The framework illuminates the relationship between interaction languages and physical devices. Such relationships are useful for eliciting design criteria, for classifying existing multifeature systems (Nigay 1994) and for evaluating the usability of a system. In this paper, we focus on usability aspects and show how the usability of a system can be correlated with the relationships that the system is able to maintain between the interaction languages and the devices it supports. We then depart from the HCI perspective to consider the implications},
  booktitle  = {Multimedia {Interfaces}: {Research} and {Applications}, chapter 9},
  publisher  = {AAAI Press},
  author     = {{Laurence Nigay} and Coutaz, Joëlle},
  year       = {1997}
}

@inproceedings{laurillau,
  title      = {{IOWAState}: implementation models and design patterns for identity-aware user interfaces based on state machines},
  shorttitle = {{IOWAState}},
  url        = {http://dl.acm.org/citation.cfm?id=2480299},
  urldate    = {2016-04-25},
  booktitle  = {Proceedings of the 5th {ACM} {SIGCHI} symposium on {Engineering} interactive computing systems},
  publisher  = {ACM},
  author     = {Laurillau, Yann},
  year       = {2013},
  pages      = {59--68},
  file       = {IOWAState_-_implementation_models_and_design_patterns_for_identity-aware_user_interfaces_based_on_state_machines.pdf:/home/alan/gdrive/zotero/storage/8DK44EQN/IOWAState_-_implementation_models_and_design_patterns_for_identity-aware_user_interfaces_based_on_state_machines.pdf:application/pdf}
}

@inproceedings{limbourg_usixml:_2004,
  title      = {{USIXML}: {A} {User} {Interface} {Description} {Language} {Supporting} {Multiple} {Levels} of {Independence}.},
  shorttitle = {{USIXML}},
  url        = {http://www.pst.informatik.uni-muenchen.de/~baumeist/icwe/ws/ws4/DIWE2004-Limbourg.pdf},
  urldate    = {2016-05-06},
  booktitle  = {{ICWE} {Workshops}},
  author     = {Limbourg, Quentin and Vanderdonckt, Jean and Michotte, Benjamin and Bouillon, Laurent and Florins, Murielle},
  year       = {2004},
  pages      = {325--338}
}

@inproceedings{limbourg_usixml:_2005,
  location   = {Berlin, Heidelberg},
  title      = {{USIXML}: A Language Supporting Multi-path Development of User
	Interfaces},
  isbn       = {978-3-540-26097-4},
  url        = {http://dx.doi.org/10.1007/11431879_12},
  doi        = {10.1007/11431879_12},
  series     = {{EHCI}-{DSVIS}'04},
  shorttitle = {{USIXML}},
  abstract   = {{USer} Interface {eXtensible} Markup Language ({USIXML}) consists
	in a User Interface Description Language ({UIDL}) allowing designers to apply
	a multi-path development of user interfaces. In this development paradigm, a
	user interface can be specified and produced at and from different, and
	possibly multiple, levels of abstraction while maintaining the mappings
	between these levels if required. Thus, the development process can be
	initiated from any level of abstraction and proceed towards obtaining one or
	many final user interfaces for various contexts of use at other levels of
	abstraction. In this way, the model-to-model transformation, which is the
	cornerstone of Model-Driven Architecture ({MDA}), can be supported in
	multiple configurations, based on composition of three basic transformation
	types: abstraction, reification, and translation.},
  pages      = {200--220},
  booktitle  = {Proceedings of the 2004 International Conference on Engineering
	Human Computer Interaction and Interactive Systems},
  publisher  = {Springer-Verlag},
  author     = {Limbourg, Quentin and Vanderdonckt, Jean and Michotte, Benjamin and
	Bouillon, Laurent and López-Jaquero, Víctor},
  urldate    = {2016-05-06},
  date       = {2005}
}

@inproceedings{meixner_interactive_2012,
  address    = {New York, NY, USA},
  series     = {{DocEng} '12},
  title      = {Interactive {Non}-linear {Video}: {Definition} and {XML} {Structure}},
  isbn       = {978-1-4503-1116-8},
  shorttitle = {Interactive {Non}-linear {Video}},
  url        = {http://doi.acm.org/10.1145/2361354.2361367},
  doi        = {10.1145/2361354.2361367},
  abstract   = {A literature review on the term "interactive video" and "interactive non-linear video" revealed different levels of interaction in varying definitions. We give a formal definition of the term "interactive non-linear video" to clarify the elements and possible relations between elements contained in such videos. Furthermore, we introduce a new event-based XML format consisting of four required and two optional elements to describe this form of video. A scene graph consisting of scenes with triggers for annotations builds the core of the format. Formal definition and XML format are both illustrated by a real world example.},
  urldate    = {2015-12-13},
  booktitle  = {Proceedings of the 2012 {ACM} {Symposium} on {Document} {Engineering}},
  publisher  = {ACM},
  author     = {Meixner, Britta and Kosch, Harald},
  year       = {2012},
  pages      = {49--58}
}

@misc{microsoft_getting_nodate,
  title   = {Getting {Started} {With} {XInput}},
  url     = {https://msdn.microsoft.com/en-us/library/windows/desktop/ee417001#multiple_controllers},
  urldate = {2016-08-02},
  author  = {{Microsoft}}
}

@misc{microsoft_speech_2003,
  title   = {Speech {Application} {Language} {Tags} ({SALT})},
  url     = {https://msdn.microsoft.com/en-us/library/ms994629.aspx},
  urldate = {2016-03-03},
  author  = {{Microsoft}},
  year    = {2003}
}

@inproceedings{moraes_lua2ncl:_2016,
  title      = {Lua2NCL: {Framework} for {Textual} {Authoring} of {NCL} {Applications} using {Lua}},
  shorttitle = {Lua2NCL},
  url        = {http://dl.acm.org/citation.cfm?id=2976851},
  urldate    = {2017-07-17},
  booktitle  = {Proceedings of the 22nd {Brazilian} {Symposium} on {Multimedia} and the {Web}},
  publisher  = {ACM},
  author     = {Moraes, Daniel de Sousa and Damasceno, André Luiz de B. and Busson, Antonio José G. and Soares Neto, Carlos de Salles},
  year       = {2016},
  pages      = {47--54}
}

@article{moreno_extending_2017,
  title    = {Extending {Hypermedia} {Conceptual} {Models} to {Support} {Hyperknowledge} {Specifications}},
  volume   = {11},
  issn     = {1793-351X},
  url      = {http://www.worldscientific.com/doi/abs/10.1142/S1793351X17400037},
  doi      = {10.1142/S1793351X17400037},
  abstract = {Most multimedia documents available today are agnostic to data semantics. Moreover, their specification language offers little to ease authoring of meaningful content. In this paper, we present the main entities of a new version (3.1) of the Nested Context Model (NCM), which concentrate efforts at integrating support for enriched concept description to the model. These extensions enable the specification of relationships between concept descriptions and multimedia content in the hypermedia way, composing what we call hyperknowledge in this paper. NCM previous version (3.0) is a hypermedia conceptual model. NCL (Nested Context Language), which is part of international standards and ITU recommendations, was engineered according to NCM 3.0 definitions. The extensions discussed in this paper contribute not only for advances in the NCL, but mainly as a conceptual model for hyperknowledge document engineering.},
  number   = {01},
  urldate  = {2017-05-29},
  journal  = {International Journal of Semantic Computing},
  author   = {Moreno, Marcio Ferreira and Brandao, Rafael and Cerqueira, Renato},
  month    = mar,
  year     = {2017},
  pages    = {43--64},
  file     = {10.1142@S1793351X17400037.pdf:/home/alan/gdrive/zotero/storage/QT9QXATJ/10.1142@S1793351X17400037.pdf:application/pdf}
}

@online{mozilla_dom,
  title      = {{DOM} {API}: Node},
  url        = {https://developer.mozilla.org/en-US/docs/Web/API/Node},
  titleaddon = {Mozilla Developer Network},
  author     = {{Mozilla}},
  urldate    = {2017-09-04}
}

@incollection{muller-tomfelde_introduction:_2010,
  title      = {Introduction: {A} {Short} {History} of {Tabletop} {Research}, {Technologies}, and {Products}},
  copyright  = {©2010 Springer-Verlag London Limited},
  isbn       = {978-1-84996-112-7 978-1-84996-113-4},
  shorttitle = {Introduction},
  url        = {http://link.springer.com/chapter/10.1007/978-1-84996-113-4_1},
  language   = {en},
  urldate    = {2015-04-12},
  booktitle  = {Tabletops - {Horizontal} {Interactive} {Displays}},
  publisher  = {Springer London},
  author     = {Müller-Tomfelde, Christian and Fjeld, Morten},
  editor     = {Müller-Tomfelde, Christian},
  year       = {2010},
  pages      = {1--24},
  file       = {Introduction_-_A_Short_History_of_Tabletop_Research,_Technologies,_and_Products.pdf:/home/alan/gdrive/zotero/storage/RPZ9RBPQ/Introduction_-_A_Short_History_of_Tabletop_Research,_Technologies,_and_Products.pdf:application/pdf}
}


@inproceedings{neto_tal_2012,
  location  = {New York, {NY}, {USA}},
  title     = {{TAL} Processor for Hypermedia Applications},
  isbn      = {978-1-4503-1116-8},
  url       = {http://doi.acm.org/10.1145/2361354.2361369},
  doi       = {10.1145/2361354.2361369},
  abstract  = {{TAL} (Template Authoring Language) is a specification language
	for hypermedia document templates. Templates describe application families
	with structural and semantic similarities. In {TAL}, templates not only
	define design patterns that applications must follow, but also constraints on
	the use of these patterns. A template must be processed together with a
	padding document giving rise to a new document in some specification
	language, called target language. {TAL} supports the description of templates
	independently of the languages used to specify target and padding documents.
	Usually a specific processor is required for each target language and for
	each padding document used. This paper concerns {TAL} processors. However, we
	should note that the proposal can be easily extended to any other solution
	used to define templates. Any pattern language and any language used to
	define constraints could be used instead of {TAL}. The {TAL} processor
	architecture is general and it is discussed when presenting the processor
	framework. As an instantiation example, an implementation of a {TAL}
	Processor targeting {NCL} (the declarative language of Ginga {DTV}
	middleware) is examined, and also another one targeting {HTML}-based
	middleware. The use of wizards for defining padding documents is also
	discussed in the examples of the proposed architecture instantiation.},
  pages     = {69--78},
  booktitle = {Proceedings of the 2012 {ACM} Symposium on Document Engineering},
  publisher = {{ACM}},
  author    = {Neto, Carlos S. Soares and Pinto, Hedvan F. and Soares, Luiz
	Fernando G.},
  urldate   = {2015-04-14},
  date      = {2012}
}

@online{openmobilealliance_wag_2001,
  title   = {{WAG} {UAProf}},
  url     = {http://www.openmobilealliance.org/Technical/wapindex.aspx},
  author  = {{OpenMobileAlliance}},
  urldate = {2016-08-02},
  date    = {2001}
}

@incollection{oviatt_multimodal_2007,
  series    = {Human {Factors} and {Ergonomics}},
  title     = {Multimodal {Interfaces}},
  isbn      = {978-0-8058-5870-9},
  url       = {http://dx.doi.org/10.1201/9781410615862.ch21},
  urldate   = {2016-04-11},
  booktitle = {The {Human}-{Computer} {Interaction} {Handbook}},
  publisher = {CRC Press},
  author    = {Oviatt, Sharon},
  month     = sep,
  year      = {2007},
  pages     = {413--432},
  file      = {Multimodal_Interfaces.pdf:/home/alan/gdrive/zotero/storage/T646NQ4I/Multimodal_Interfaces.pdf:application/pdf}
}

@article{rowe_looking_2013,
  title    = {Looking {Forward} 10 {Years} to {Multimedia} {Successes}},
  volume   = {9},
  issn     = {1551-6857},
  url      = {http://doi.acm.org/10.1145/2490825},
  doi      = {10.1145/2490825},
  abstract = {A panel at ACM Multimedia 2012 addressed research successes in the past 20 years. While the panel focused on the past, this article discusses successes since the ACM SIGMM 2003 Retreat and suggests research directions in the next ten years. While significant progress has been made, more research is required to allow multimedia to impact our everyday computing environment. The importance of hardware changes on future research directions is discussed. We believe ubiquitous computing—meaning abundant computation and network bandwidth—should be applied in novel ways to solve multimedia grand challenges and continue the IT revolution of the past century.},
  number   = {1},
  urldate  = {2015-04-11},
  journal  = {ACM Transactions on Multimedia Computing, Communications, and Applications},
  author   = {Rowe, Lawrence A.},
  year     = {2013},
  pages    = {37:1--37:7},
  file     = {Looking_Forward_10_Years_to_Multimedia_Successes.pdf:/home/alan/gdrive/zotero/storage/6NBSUZNV/Looking_Forward_10_Years_to_Multimedia_Successes.pdf:application/pdf}
}

@article{santos_xtemplate_2012,
  title      = {{XTemplate} 3.0: {Spatio}-temporal {Semantics} and {Structure} {Reuse} for {Hypermedia} {Compositions}},
  volume     = {61},
  issn       = {1380-7501},
  shorttitle = {{XTemplate} 3.0},
  url        = {http://dx.doi.org/10.1007/s11042-011-0732-2},
  doi        = {10.1007/s11042-011-0732-2},
  abstract   = {The use of declarative languages in digital TV systems, as well as IPTV systems, facilitates the creation of interactive applications. However, when an application becomes more complex, with many user interactions, for example, the hypermedia document that describes that application becomes bigger, having many lines of XML code. Thus, specification reuse is crucial for an efficient application development process. This paper proposes the XTemplate 3.0 language, which allows the creation of NCL hypermedia composite templates. Templates define generic structures of nodes and links to be added to a document composition, providing spatio-temporal synchronization semantics to it. The use of hypermedia composite templates aims at facilitating the authoring work, allowing the reuse of hypermedia document common specifications. Using composite templates, hypermedia documents become simpler and easier to be created. The 3.0 version of XTemplate adds new facilities to the XTemplate language, such as the possibility of specifying presentation information, the attribution of values to variables and connector parameters during template processing time and the template ability to extend other templates. As an application of XTemplate, this work extends the NCL 3.0 declarative language with XTemplate, adding semantics to NCL contexts and providing document structure reuse. In addition, this paper also presents two authoring tools: the template processor and the wizard to create NCL documents using templates. The wizard tool allows the author to choose a template included in a template base and create an NCL document using that template. The template processor transforms an NCL document using templates into a standard NCL 3.0 document according to digital TV and IPTV standards.},
  number     = {3},
  urldate    = {2016-01-06},
  journal    = {Multimedia Tools Appl.},
  author     = {Santos, Joel André and Muchaluat-Saade, Débora Christina},
  month      = dec,
  year       = {2012},
  pages      = {645--673}
}

@article{schnelle-walka_jvoicexml_2013,
  title    = {{JVoiceXML} as a modality component in the {W}3C multimodal architecture},
  volume   = {7},
  issn     = {1783-7677, 1783-8738},
  url      = {http://link.springer.com/article/10.1007/s12193-013-0119-y},
  doi      = {10.1007/s12193-013-0119-y},
  abstract = {Research regarding multimodal interaction led to a multitude of proposals for suitable software architectures. With all architectures describing multimodal systems differently, interoperability is severely hindered. The W3C MMI architecture is a proposed recommendation for a common architecture. In this article, we describe our experiences integrating JVoiceXML into the W3C MMI architecture and identify general limitations with regard to the available design space.},
  language = {en},
  number   = {3},
  urldate  = {2014-05-19},
  journal  = {Journal on Multimodal User Interfaces},
  author   = {Schnelle-Walka, Dirk and Radomski, Stefan and Mühlhäuser, Max},
  month    = nov,
  year     = {2013},
  pages    = {183--194},
  file     = {JVoiceXML_as_a_modality_component_in_the_W3C_multimodal_architecture.pdf:/home/alan/gdrive/zotero/storage/V6P2WKSS/JVoiceXML_as_a_modality_component_in_the_W3C_multimodal_architecture.pdf:application/pdf}
}

@article{shapiro_beyond_2016,
  title      = {Beyond {Blocks}: {Syntax} and {Semantics}},
  volume     = {59},
  issn       = {0001-0782},
  shorttitle = {Beyond {Blocks}},
  url        = {http://doi.acm.org/10.1145/2903751},
  doi        = {10.1145/2903751},
  abstract   = {How the future of general-purpose programming tools could include blocks-based structured editing, and how we should study students transitioning to text-based programming tools.},
  number     = {5},
  urldate    = {2017-02-21},
  journal    = {Commun. ACM},
  author     = {Shapiro, R. Benjamin and Ahrens, Matthew},
  month      = apr,
  year       = {2016},
  pages      = {39--41},
  file       = {ACM Full Text PDF:/home/alan/gdrive/zotero/storage/2TGHBVQH/Beyond Blocks Syntax and Semantics.pdf:application/pdf}
}

@inproceedings{silva_jns:_2013,
  title      = {{JNS}: {An} alternative authoring language for specifying {NCL} multimedia documents},
  shorttitle = {{JNS}},
  doi        = {10.1109/ICMEW.2013.6618452},
  abstract   = {This paper presents JNS - JSON NCL Script, a declarative authoring language for describing NCL multimedia documents. NCL (Nested Context Language) is a standard language used in the Brazilian Digital Television System and in the ITU H.761 IPTV services recommendation for specifying interactive multimedia applications. Once NCL is XML-based, even simple NCL documents have several lines of code. JNS provides a new way of writing an NCL document, offering a more compact textual representation and providing more expressiveness to NCL. JNS is based on the Java Script Object Notation (JSON) instead of the XML standard. This work presents an overview of the JNS language and the new functionalities it brings to NCL document specification. In addition, comparisons between JNS and NCL specifications are shown.},
  booktitle  = {2013 {IEEE} {International} {Conference} on {Multimedia} and {Expo} {Workshops} ({ICMEW})},
  author     = {Silva, E. C. O. and Santos, J. A. F. dos and Muchaluat-Saade, D. C.},
  month      = jul,
  year       = {2013},
  pages      = {1--6}
}

@inproceedings{soares_multiple_2009,
  address   = {New York, NY, USA},
  title     = {Multiple {Exhibition} {Devices} in {DTV} {Systems}},
  isbn      = {978-1-60558-608-3},
  url       = {http://doi.acm.org/10.1145/1631272.1631312},
  doi       = {10.1145/1631272.1631312},
  abstract  = {Nested Context Language (NCL) is the declarative language of the Brazilian Terrestrial Digital TV System. NCL is part of ISDB (International Standard for Digital Broadcasting) standards and also the ITU-T Recommendation H.761 for IPTV services. This paper presents, discusses, and illustrates the NCL hierarchical control model for multiple exhibition device support. Based on this model, multiple devices are orchestrated to run a DTV application in cooperation. Two types of multiple device exhibitions are distinguished. Those where the same content is shown in a set of devices under a unique control, and those where content is under each individual device control, working completely independent. In this last case, depending on viewer interactions, the resulting presented content can differ from a device to another. Examples of NCL applications using both options are presented and discussed.},
  urldate   = {2015-05-07},
  booktitle = {Proceedings of the 17th {ACM} {International} {Conference} on {Multimedia}},
  publisher = {ACM},
  author    = {Soares, Luiz Fernando Gomes and Costa, Romualdo M.R. and Moreno, Marcio Ferreira and Moreno, Marcelo F.},
  year      = {2009},
  pages     = {281--290}
}

@article{soares_nested_2009,
  title   = {Nested {Context} {Model} 3.0: {Part} 1 – {NCM} {Core}},
  issn    = {0103-9741},
  url     = {ftp://obaluae.inf.puc-rio.br/pub/docs/techreports/05_18_soares.pdf},
  urldate = {2016-08-02},
  journal = {Monographs in Computer Science PUC-Rio Inf MCC18/05},
  author  = {Soares, Luiz Fernando Gomes},
  year    = {2009},
  file    = {Nested_Context_Model_3.0_-_Part_1_–_NCM_Core.pdf:/home/alan/gdrive/zotero/storage/QB2XJ4NC/Nested_Context_Model_3.0_-_Part_1_–_NCM_Core.pdf:application/pdf}
}

@article{stefik_wysiwis_1987,
  title      = {{WYSIWIS} {Revised}: {Early} {Experiences} with {Multiuser} {Interfaces}},
  volume     = {5},
  issn       = {1046-8188},
  shorttitle = {{WYSIWIS} {Revised}},
  url        = {http://doi.acm.org/10.1145/27636.28056},
  doi        = {10.1145/27636.28056},
  abstract   = {WYSIWIS (What You See Is What I See) is a foundational abstraction for multiuser interfaces that expresses many of the characteristics of a chalkboard in face-to-face meetings. In its strictest interpretation, it means that everyone can also see the same written information and also see where anyone else is pointing. In our attempts to build software support for collaboration in meetings, we have discovered that WYSIWIS is crucial, yet too inflexible when strictly enforced. This paper is about the design issues and choices that arose in our first generation of meeting tools based on WYSIWIS. Several examples of multiuser interfaces that start from this abstraction are presented. These tools illustrate that there are inherent conflicts between the needs of a group and the needs of individuals, since user interfaces compete for the same display space and meeting time. To help minimize the effect of these conflicts, constraints were relaxed along four key dimensions of WYSIWIS: display space, time of display, subgroup population, and congruence of view. Meeting tools must be designed to support the changing needs of information sharing during process transitions, as subgroups are formed and dissolved, as individuals shift their focus of activity, and as the group shifts from multiple parallel activities to a single focused activity and back again.},
  number     = {2},
  urldate    = {2016-03-22},
  journal    = {ACM Trans. Inf. Syst.},
  author     = {Stefik, M. and Bobrow, D. G. and Foster, G. and Lanning, S. and Tatar, D.},
  month      = apr,
  year       = {1987},
  pages      = {147--167},
  file       = {ACM Full Text PDF:/home/alan/gdrive/zotero/storage/29LXZLZV/WYSIWIS Revised Early Experiences with Multiuser Interfaces.pdf:application/pdf}
}
@article{turk_multimodal_2014,
  title      = {Multimodal interaction: {A} review},
  volume     = {36},
  issn       = {0167-8655},
  shorttitle = {Multimodal interaction},
  url        = {http://www.sciencedirect.com/science/article/pii/S0167865513002584},
  doi        = {10.1016/j.patrec.2013.07.003},
  abstract   = {People naturally interact with the world multimodally, through both parallel and sequential use of multiple perceptual modalities. Multimodal human–computer interaction has sought for decades to endow computers with similar capabilities, in order to provide more natural, powerful, and compelling interactive experiences. With the rapid advance in non-desktop computing generated by powerful mobile devices and affordable sensors in recent years, multimodal research that leverages speech, touch, vision, and gesture is on the rise. This paper provides a brief and personal review of some of the key aspects and issues in multimodal interaction, touching on the history, opportunities, and challenges of the area, especially in the area of multimodal integration. We review the question of early vs. late integration and find inspiration in recent evidence in biological sensory integration. Finally, we list challenges that lie ahead for research in multimodal human–computer interaction.},
  urldate    = {2014-05-30},
  journal    = {Pattern Recognition Letters},
  author     = {Turk, Matthew},
  year       = {2014},
  pages      = {189--195},
  file       = {Multimodal_interaction_-_A_review.pdf:/home/alan/gdrive/zotero/storage/ER9BRNNI/Multimodal_interaction_-_A_review.pdf:application/pdf}
}

@incollection{vilhjalmsson_behavior_2007,
  title      = {The {Behavior} {Markup} {Language}: {Recent} {Developments} and {Challenges}},
  copyright  = {©2007 Springer-Verlag Berlin Heidelberg},
  isbn       = {978-3-540-74996-7 978-3-540-74997-4},
  shorttitle = {The {Behavior} {Markup} {Language}},
  url        = {http://link.springer.com/chapter/10.1007/978-3-540-74997-4_10},
  abstract   = {Since the beginning of the SAIBA effort to unify key interfaces in the multi-modal behavior generation process, the Behavior Markup Language (BML) has both gained ground as an important component in many projects worldwide, and continues to undergo further refinement. This paper reports on the progress made in the last year in further developing BML. It discusses some of the key challenges identified that the effort is facing, and reviews a number of projects that already are making use of BML or support its use.},
  language   = {en},
  urldate    = {2015-06-02},
  booktitle  = {Intelligent {Virtual} {Agents}},
  publisher  = {Springer Berlin Heidelberg},
  author     = {Vilhjálmsson, Hannes and Cantelmo, Nathan and Cassell, Justine and Chafai, Nicolas E. and Kipp, Michael and Kopp, Stefan and Mancini, Maurizio and Marsella, Stacy and Marshall, Andrew N. and Pelachaud, Catherine and Ruttkay, Zsofi and Thórisson, Kristinn R. and Welbergen, Herwin van and Werf, Rick J. van der},
  editor     = {Pelachaud, Catherine and Martin, Jean-Claude and André, Elisabeth and Chollet, Gérard and Karpouzis, Kostas and Pelé, Danielle},
  year       = {2007},
  pages      = {99--111},
  file       = {The_Behavior_Markup_Language_-_Recent_Developments_and_Challenges.pdf:/home/alan/gdrive/zotero/storage/SWIIDUAH/The_Behavior_Markup_Language_-_Recent_Developments_and_Challenges.pdf:application/pdf}
}

@misc{w3c_dom4_2015,
  title    = {{DOM}4},
  url      = {https://www.w3.org/TR/dom/},
  language = {en},
  urldate  = {2017-09-04},
  author   = {W3C},
  year     = {2015}
}

@misc{w3c_emma:_2009,
  title   = {{EMMA}: {Extensible} {MultiModal} {Annotation} markup language},
  url     = {http://www.w3.org/TR/2009/REC-emma-20090210/},
  urldate = {2016-03-03},
  author  = {W3C},
  year    = {2009}
}

@misc{w3c_html_2014,
  title   = {{HTML} 5},
  url     = {https://www.w3.org/TR/html5/},
  urldate = {2016-12-09},
  author  = {W3C},
  year    = {2014}
}

@misc{w3c_ink_2011,
  title   = {Ink {Markup} {Language} ({InkML})},
  url     = {http://www.w3.org/TR/2011/REC-InkML-20110920/},
  urldate = {2016-08-02},
  author  = {W3C},
  year    = {2011}
}

@misc{w3c_multimodal_2003,
  title   = {Multimodal {Interaction} {Framework}},
  url     = {www.w3.org/TR/mmi-framework/},
  urldate = {2016-03-03},
  author  = {W3C},
  year    = {2003},
  file    = {Multimodal_Interaction_Framework.pdf:/home/alan/gdrive/zotero/storage/WWEC9ZQB/Multimodal_Interaction_Framework.pdf:application/pdf}
}


@misc{w3c_multimodal_2012,
  title   = {Multimodal {Architecture} and {Interfaces}},
  url     = {http://www.w3.org/TR/mmi-arch/},
  urldate = {2016-08-02},
  author  = {W3C},
  year    = {2012},
  file    = {Multimodal_Architecture_and_Interfaces.pdf:/home/alan/gdrive/zotero/storage/XDRIQJUV/Multimodal_Architecture_and_Interfaces.pdf:application/pdf}
}

@misc{w3c_rdf/xml_2014,
  title   = {{RDF}/{XML} {Syntax} {Specification}},
  url     = {https://www.w3.org/TR/REC-rdf-syntax/},
  urldate = {2016-08-02},
  author  = {W3C},
  year    = {2014}
}

@misc{w3c_sparql_2008,
  title   = {{SPARQL} {Query} {Language} for {RDF}},
  url     = {https://www.w3.org/TR/rdf-sparql-query/},
  urldate = {2016-08-02},
  author  = {W3C},
  year    = {2008}
}

@misc{w3c_state_2012,
  title   = {State {Chart} {XML} ({SCXML}): {State} {Machine} {Notation} for {Control} {Abstraction}},
  url     = {http://www.w3.org/TR/scxml/},
  urldate = {2016-08-02},
  author  = {W3C},
  year    = {2012}
}

@misc{w3c_voice_2007,
  title   = {Voice {Extensible} {Markup} {Language} ({VoiceXML}) 2.1},
  url     = {http://www.w3.org/TR/voicexml21/},
  urldate = {2016-03-03},
  author  = {W3C},
  year    = {2007}
}

@misc{w3c_xhtml_2000,
  title   = {{XHTML} 1.0: {The} {Extensible} {HyperText} {Markup} {Language}},
  url     = {https://www.w3.org/TR/2000/REC-xhtml1-20000126/},
  urldate = {2016-10-11},
  author  = {W3C},
  year    = {2000}
}

@misc{w3c_xhtml+voice_2001,
  title   = {{XHTML}+{Voice} {Profile} 1.0},
  url     = {http://www.w3.org/TR/xhtml+voice/},
  urldate = {2016-08-02},
  author  = {W3C},
  year    = {2001}
}

@inproceedings{wang_salt:_2002,
  title     = {{SALT}: {A} {Spoken} {Language} {Interface} for {Web}-based {Multimodal} {Dialog} {Systems}},
  url       = {http://research.microsoft.com/apps/pubs/default.aspx?id=77497},
  booktitle = {Proc. {Int}. {Conf}. on {Spoken} {Language} {Processing}},
  author    = {Wang, Kuansan},
  year      = {2002}
}scriptsize